{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary packages\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('file.tar.gz', <http.client.HTTPMessage at 0x220c941db00>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving urls info in tar file\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve (\"https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/20_newsgroups.tar.gz\", \"file.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting contents of tar file\n",
    "import tarfile\n",
    "tar = tarfile.open(\"file.tar.gz\")\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating list of stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)\n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = [f for f in os.listdir('./20_newsgroups')]\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add all words and their counts to dictionary 'words'\n",
    "words = {}\n",
    "\n",
    "for d in directory:\n",
    "    files = os.listdir('./20_newsgroups/' + d)\n",
    "    \n",
    "    for f in files:\n",
    "        path = './20_newsgroups/' + d + '/' + f\n",
    "        text = open(path, 'r', errors='ignore').read()\n",
    "        for word in text.split():\n",
    "            word = word.lower()\n",
    "            #only alphabetical words valid\n",
    "            n = len(word)\n",
    "            if (word.isalpha() == False and word[0:n-1].isalpha() == False):  \n",
    "                continue\n",
    "            if (word[n-1] == ':'):\n",
    "                continue\n",
    "            if (word[n-1].isalpha() == False):\n",
    "                word = word[0:n-1]\n",
    "            if word not in stops:\n",
    "                if word in words:\n",
    "                    words[word] += 1\n",
    "                else:\n",
    "                    words[word] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort words according to frequency\n",
    "import operator\n",
    "sorted_x= sorted(words.items(), key=operator.itemgetter(1))\n",
    "sorted_x.reverse()\n",
    "words2 = sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = words2[0:3002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert new words list back to dictionary\n",
    "\n",
    "words_dict = {}\n",
    "for t in new_words:\n",
    "    words_dict[t[0]] = t[1]\n",
    "    \n",
    "#words_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#delete irrelevant words\n",
    "\n",
    "del(words_dict['gmt'])\n",
    "del(words_dict['apr'])\n",
    "#words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    0.0\n",
      "B    0.0\n",
      "C    0.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C\n",
       "0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas=['A', 'B', 'C']\n",
    "df = pd.DataFrame(columns=alphas)\n",
    "arr = np.zeros(3)\n",
    "ser = pd.Series(arr, index = alphas)\n",
    "print(ser)\n",
    "df = df.append(ser, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dictionary and frequencies to data frame\n",
    "\n",
    "word_list = list(words_dict.keys())\n",
    "df = pd.DataFrame(columns = word_list)     #dataframe for storing dictionary of words\n",
    "Y = []\n",
    "i = 0\n",
    "for d in directory:\n",
    "    files = os.listdir('./20_newsgroups/' + d)\n",
    "    \n",
    "    for f in files:\n",
    "        arr = np.zeros(len(word_list))\n",
    "        ser = pd.Series(arr, index = word_list)   #need to convert to series to append to datafame\n",
    "        df = df.append(ser, ignore_index=True)\n",
    "        path = './20_newsgroups/' + d + '/' + f\n",
    "        text = open(path,  'r', errors='ignore').read()\n",
    "        for word in text.split():                 #for each word, increase count if present in word list\n",
    "            if word.lower() in word_list:\n",
    "                df.loc[len(df) - 1, word.lower()] += 1\n",
    "                \n",
    "        Y.append(i)\n",
    "        \n",
    "    i = i+1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(Y)\n",
    "y = np.array(Y)\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to fit training examples\n",
    "def fit(X_train, Y_train):\n",
    "    result = {}         #dictionary to store counts of each word for particular class\n",
    "    class_values = set(Y_train)   #possible class values\n",
    "    for current_class in class_values:\n",
    "        result[current_class] = {}\n",
    "        result[\"total_data\"] = len(Y_train)   \n",
    "        current_class_rows = (Y_train == current_class)   #choose only rows which belong to current class\n",
    "        X_train_current = X_train[current_class_rows]    #pick X and Y for these rows\n",
    "        Y_train_current = Y_train[current_class_rows]\n",
    "        num_words = len(word_list)           \n",
    "        result[current_class][\"total_count\"] = 0    #total number of words belonging to current class\n",
    "        for j in range(num_words):\n",
    "            result[current_class][word_list[j]] = (X_train_current[:, j]).sum()    #add frequencies of word j in current class\n",
    "            result[current_class][\"total_count\"] += (X_train_current[:, j]).sum() \n",
    "            \n",
    "                \n",
    "    return result\n",
    "\n",
    "\n",
    "def probability(dictionary, x, current_class):\n",
    "    output = np.log(dictionary[current_class][\"total_count\"]) - np.log(dictionary[\"total_data\"])\n",
    "    for j in range(len(word_list)):\n",
    "\n",
    "        num = dictionary[current_class][word_list[j]] + 1   #count of word in current class\n",
    "        den = dictionary[current_class][\"total_count\"] + len(word_list)   #count of all words in current_class\n",
    "        current_word_probablity = np.log(num) - np.log(den)  #divide - use log\n",
    "        #for current testing example, multiply probability with number of times the word appears and add to answer\n",
    "        output = output + current_word_probablity*x[j]\n",
    "    return output\n",
    "\n",
    "def predictSinglePoint(dictionary, x):\n",
    "    classes = dictionary.keys()\n",
    "    best_p = -1000\n",
    "    best_class = -1\n",
    "    first_run = True\n",
    "    for current_class in classes:\n",
    "        if (current_class == \"total_data\"):\n",
    "            continue\n",
    "        #find class which maximises total probability for testing example\n",
    "        p_current_class = probability(dictionary, x, current_class)\n",
    "        if (first_run or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class\n",
    "\n",
    "#main function to predict class for given testing dataset and dictionary computed in fit.\n",
    "def predict(dictionary, X_test):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        #for each testing example\n",
    "        x_class = predictSinglePoint(dictionary, x)\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit training examples and predict for test\n",
    "dict_train = fit(X_train, Y_train)\n",
    "y_pred = predict(dict_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 18,\n",
       " 1,\n",
       " 17,\n",
       " 8,\n",
       " 13,\n",
       " 19,\n",
       " 12,\n",
       " 2,\n",
       " 11,\n",
       " 17,\n",
       " 15,\n",
       " 19,\n",
       " 7,\n",
       " 15,\n",
       " 14,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 17,\n",
       " 16,\n",
       " 19,\n",
       " 4,\n",
       " 16,\n",
       " 11,\n",
       " 13,\n",
       " 0,\n",
       " 2,\n",
       " 15,\n",
       " 18,\n",
       " 11,\n",
       " 8,\n",
       " 12,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 17,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 18,\n",
       " 17,\n",
       " 1,\n",
       " 13,\n",
       " 19,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 12,\n",
       " 15,\n",
       " 16,\n",
       " 12,\n",
       " 3,\n",
       " 18,\n",
       " 19,\n",
       " 12,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 12,\n",
       " 10,\n",
       " 2,\n",
       " 1,\n",
       " 15,\n",
       " 11,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 12,\n",
       " 12,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 13,\n",
       " 9,\n",
       " 19,\n",
       " 0,\n",
       " 1,\n",
       " 16,\n",
       " 5,\n",
       " 3,\n",
       " 13,\n",
       " 13,\n",
       " 6,\n",
       " 15,\n",
       " 15,\n",
       " 1,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 19,\n",
       " 2,\n",
       " 9,\n",
       " 16,\n",
       " 7,\n",
       " 16,\n",
       " 10,\n",
       " 13,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 19,\n",
       " 8,\n",
       " 10,\n",
       " 17,\n",
       " 17,\n",
       " 10,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 16,\n",
       " 7,\n",
       " 18,\n",
       " 0,\n",
       " 9,\n",
       " 17,\n",
       " 18,\n",
       " 1,\n",
       " 12,\n",
       " 3,\n",
       " 10,\n",
       " 13,\n",
       " 2,\n",
       " 15,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 18,\n",
       " 11,\n",
       " 5,\n",
       " 0,\n",
       " 18,\n",
       " 6,\n",
       " 18,\n",
       " 0,\n",
       " 12,\n",
       " 10,\n",
       " 0,\n",
       " 16,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 15,\n",
       " 16,\n",
       " 18,\n",
       " 16,\n",
       " 7,\n",
       " 11,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 17,\n",
       " 12,\n",
       " 15,\n",
       " 16,\n",
       " 19,\n",
       " 12,\n",
       " 2,\n",
       " 9,\n",
       " 19,\n",
       " 13,\n",
       " 9,\n",
       " 17,\n",
       " 3,\n",
       " 9,\n",
       " 11,\n",
       " 13,\n",
       " 17,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 15,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 11,\n",
       " 4,\n",
       " 18,\n",
       " 13,\n",
       " 1,\n",
       " 19,\n",
       " 13,\n",
       " 15,\n",
       " 5,\n",
       " 16,\n",
       " 13,\n",
       " 6,\n",
       " 16,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 15,\n",
       " 18,\n",
       " 13,\n",
       " 6,\n",
       " 2,\n",
       " 18,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 13,\n",
       " 14,\n",
       " 17,\n",
       " 12,\n",
       " 19,\n",
       " 1,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 12,\n",
       " 16,\n",
       " 6,\n",
       " 17,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 9,\n",
       " 16,\n",
       " 5,\n",
       " 14,\n",
       " 8,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 12,\n",
       " 15,\n",
       " 18,\n",
       " 16,\n",
       " 17,\n",
       " 1,\n",
       " 15,\n",
       " 11,\n",
       " 19,\n",
       " 13,\n",
       " 19,\n",
       " 18,\n",
       " 6,\n",
       " 5,\n",
       " 19,\n",
       " 15,\n",
       " 11,\n",
       " 15,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 12,\n",
       " 5,\n",
       " 4,\n",
       " 10,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 5,\n",
       " 17,\n",
       " 1,\n",
       " 11,\n",
       " 3,\n",
       " 14,\n",
       " 0,\n",
       " 9,\n",
       " 13,\n",
       " 13,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 19,\n",
       " 13,\n",
       " 8,\n",
       " 12,\n",
       " 9,\n",
       " 18,\n",
       " 12,\n",
       " 4,\n",
       " 3,\n",
       " 16,\n",
       " 0,\n",
       " 16,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 12,\n",
       " 10,\n",
       " 5,\n",
       " 15,\n",
       " 4,\n",
       " 10,\n",
       " 19,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 10,\n",
       " 9,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 1,\n",
       " 11,\n",
       " 12,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 15,\n",
       " 5,\n",
       " 13,\n",
       " 12,\n",
       " 1,\n",
       " 7,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 16,\n",
       " 14,\n",
       " 18,\n",
       " 16,\n",
       " 4,\n",
       " 14,\n",
       " 18,\n",
       " 4,\n",
       " 13,\n",
       " 15,\n",
       " 8,\n",
       " 4,\n",
       " 13,\n",
       " 11,\n",
       " 0,\n",
       " 4,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 12,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 15,\n",
       " 11,\n",
       " 3,\n",
       " 18,\n",
       " 0,\n",
       " 14,\n",
       " 14,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 18,\n",
       " 4,\n",
       " 18,\n",
       " 12,\n",
       " 6,\n",
       " 10,\n",
       " 18,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 19,\n",
       " 12,\n",
       " 13,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 16,\n",
       " 16,\n",
       " 11,\n",
       " 8,\n",
       " 11,\n",
       " 6,\n",
       " 2,\n",
       " 15,\n",
       " 5,\n",
       " 15,\n",
       " 16,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 15,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 18,\n",
       " 10,\n",
       " 1,\n",
       " 8,\n",
       " 16,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 15,\n",
       " 11,\n",
       " 3,\n",
       " 11,\n",
       " 3,\n",
       " 9,\n",
       " 16,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 6,\n",
       " 17,\n",
       " 6,\n",
       " 10,\n",
       " 16,\n",
       " 7,\n",
       " 0,\n",
       " 17,\n",
       " 0,\n",
       " 5,\n",
       " 17,\n",
       " 15,\n",
       " 6,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 1,\n",
       " 10,\n",
       " 5,\n",
       " 2,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 8,\n",
       " 15,\n",
       " 6,\n",
       " 14,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 15,\n",
       " 18,\n",
       " 14,\n",
       " 15,\n",
       " 13,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 12,\n",
       " 13,\n",
       " 7,\n",
       " 14,\n",
       " 18,\n",
       " 6,\n",
       " 11,\n",
       " 15,\n",
       " 2,\n",
       " 7,\n",
       " 18,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 18,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 9,\n",
       " 0,\n",
       " 11,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 7,\n",
       " 5,\n",
       " 13,\n",
       " 13,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 10,\n",
       " 4,\n",
       " 3,\n",
       " 14,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 14,\n",
       " 12,\n",
       " 17,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 13,\n",
       " 18,\n",
       " 19,\n",
       " 18,\n",
       " 2,\n",
       " 16,\n",
       " 9,\n",
       " 14,\n",
       " 0,\n",
       " 15,\n",
       " 4,\n",
       " 1,\n",
       " 17,\n",
       " 11,\n",
       " 17,\n",
       " 0,\n",
       " 12,\n",
       " 12,\n",
       " 11,\n",
       " 6,\n",
       " 13,\n",
       " 15,\n",
       " 15,\n",
       " 6,\n",
       " 5,\n",
       " 13,\n",
       " 19,\n",
       " 12,\n",
       " 10,\n",
       " 4,\n",
       " 15,\n",
       " 16,\n",
       " 7,\n",
       " 11,\n",
       " 2,\n",
       " 17,\n",
       " 14,\n",
       " 9,\n",
       " 15,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 2,\n",
       " 13,\n",
       " 19,\n",
       " 12,\n",
       " 0,\n",
       " 5,\n",
       " 11,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 11,\n",
       " 6,\n",
       " 11,\n",
       " 3,\n",
       " 8,\n",
       " 13,\n",
       " 16,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 12,\n",
       " 10,\n",
       " 0,\n",
       " 10,\n",
       " 19,\n",
       " 18,\n",
       " 16,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 17,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 12,\n",
       " 12,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 16,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 8,\n",
       " 16,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 8,\n",
       " 19,\n",
       " 9,\n",
       " 5,\n",
       " 11,\n",
       " 3,\n",
       " 11,\n",
       " 15,\n",
       " 13,\n",
       " 3,\n",
       " 16,\n",
       " 9,\n",
       " 17,\n",
       " 14,\n",
       " 10,\n",
       " 6,\n",
       " 16,\n",
       " 10,\n",
       " 14,\n",
       " 18,\n",
       " 12,\n",
       " 14,\n",
       " 17,\n",
       " 2,\n",
       " 9,\n",
       " 18,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 12,\n",
       " 6,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 15,\n",
       " 17,\n",
       " 16,\n",
       " 12,\n",
       " 19,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 12,\n",
       " 16,\n",
       " 14,\n",
       " 6,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 14,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 3,\n",
       " 19,\n",
       " 8,\n",
       " 16,\n",
       " 0,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 15,\n",
       " 14,\n",
       " 16,\n",
       " 9,\n",
       " 11,\n",
       " 15,\n",
       " 17,\n",
       " 9,\n",
       " 9,\n",
       " 13,\n",
       " 4,\n",
       " 17,\n",
       " 6,\n",
       " 6,\n",
       " 15,\n",
       " 18,\n",
       " 10,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 12,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 13,\n",
       " 1,\n",
       " 15,\n",
       " 16,\n",
       " 18,\n",
       " 4,\n",
       " 8,\n",
       " 15,\n",
       " 3,\n",
       " 2,\n",
       " 18,\n",
       " 3,\n",
       " 17,\n",
       " 12,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 2,\n",
       " 11,\n",
       " 4,\n",
       " 11,\n",
       " 5,\n",
       " 7,\n",
       " 17,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 14,\n",
       " 11,\n",
       " 16,\n",
       " 2,\n",
       " 18,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 5,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 3,\n",
       " 14,\n",
       " 19,\n",
       " 9,\n",
       " 1,\n",
       " 18,\n",
       " 18,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 17,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 10,\n",
       " 18,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 12,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 3,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 10,\n",
       " 10,\n",
       " 1,\n",
       " 16,\n",
       " 8,\n",
       " 17,\n",
       " 3,\n",
       " 0,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 18,\n",
       " 8,\n",
       " 1,\n",
       " 14,\n",
       " 6,\n",
       " 19,\n",
       " 19,\n",
       " 6,\n",
       " 15,\n",
       " 18,\n",
       " 6,\n",
       " 0,\n",
       " 18,\n",
       " 16,\n",
       " 11,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 12,\n",
       " 19,\n",
       " 16,\n",
       " 13,\n",
       " 18,\n",
       " 19,\n",
       " 15,\n",
       " 6,\n",
       " 11,\n",
       " 6,\n",
       " 3,\n",
       " 16,\n",
       " 8,\n",
       " 5,\n",
       " 13,\n",
       " 9,\n",
       " 16,\n",
       " 15,\n",
       " 5,\n",
       " 6,\n",
       " 12,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 12,\n",
       " 6,\n",
       " 10,\n",
       " 0,\n",
       " 13,\n",
       " 4,\n",
       " 19,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 17,\n",
       " 1,\n",
       " 19,\n",
       " 3,\n",
       " 12,\n",
       " 1,\n",
       " 10,\n",
       " 18,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 15,\n",
       " 7,\n",
       " 12,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 11,\n",
       " 6,\n",
       " 11,\n",
       " 13,\n",
       " 12,\n",
       " 17,\n",
       " 16,\n",
       " 6,\n",
       " 12,\n",
       " 7,\n",
       " 3,\n",
       " 18,\n",
       " 2,\n",
       " 0,\n",
       " 15,\n",
       " 18,\n",
       " 7,\n",
       " 4,\n",
       " 19,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 16,\n",
       " 0,\n",
       " 10,\n",
       " 7,\n",
       " 18,\n",
       " 11,\n",
       " 10,\n",
       " 14,\n",
       " 15,\n",
       " 10,\n",
       " 2,\n",
       " 13,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 17,\n",
       " 16,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 10,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 17,\n",
       " 7,\n",
       " 1,\n",
       " 16,\n",
       " 12,\n",
       " 7,\n",
       " 3,\n",
       " 13,\n",
       " 3,\n",
       " 16,\n",
       " 13,\n",
       " 8,\n",
       " 15,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 14,\n",
       " 1,\n",
       " 17,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 10,\n",
       " 16,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 12,\n",
       " 12,\n",
       " 1,\n",
       " 18,\n",
       " 1,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 4,\n",
       " 16,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 17,\n",
       " 10,\n",
       " 18,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 10,\n",
       " 7,\n",
       " 12,\n",
       " 3,\n",
       " 11,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracucy for self-coded classifier\n",
    "accuracy_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       236\n",
      "           1       0.67      0.66      0.67       242\n",
      "           2       0.65      0.74      0.69       231\n",
      "           3       0.68      0.68      0.68       259\n",
      "           4       0.75      0.75      0.75       246\n",
      "           5       0.87      0.73      0.80       252\n",
      "           6       0.78      0.77      0.77       264\n",
      "           7       0.77      0.82      0.79       231\n",
      "           8       0.82      0.88      0.85       234\n",
      "           9       0.91      0.91      0.91       277\n",
      "          10       0.92      0.90      0.91       271\n",
      "          11       0.89      0.90      0.89       226\n",
      "          12       0.70      0.76      0.72       249\n",
      "          13       0.89      0.81      0.85       263\n",
      "          14       0.86      0.86      0.86       240\n",
      "          15       0.78      0.84      0.81       262\n",
      "          16       0.69      0.84      0.76       270\n",
      "          17       0.85      0.85      0.85       224\n",
      "          18       0.71      0.55      0.62       272\n",
      "          19       0.53      0.39      0.45       251\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5000\n",
      "   macro avg       0.77      0.77      0.76      5000\n",
      "weighted avg       0.77      0.77      0.76      5000\n",
      "\n",
      "[[169   1   0   1   0   0   0   3   5   1   1   0   2   2   1   9   1   1\n",
      "    1  38]\n",
      " [  0 160  23   7   6  13   4   4   0   0   0   3   6   5   9   1   0   0\n",
      "    0   1]\n",
      " [  0  14 172  16   5   9   4   0   0   1   0   2   4   0   0   0   0   0\n",
      "    3   1]\n",
      " [  0   5  26 177  25   0   7   5   1   0   0   2   9   0   1   0   0   1\n",
      "    0   0]\n",
      " [  0   4  11  20 184   0   7   3   0   0   0   0  13   2   1   0   1   0\n",
      "    0   0]\n",
      " [  1  26  22   5   3 185   1   0   0   0   0   1   5   0   3   0   0   0\n",
      "    0   0]\n",
      " [  2   2   2  15   6   0 202  11   7   1   2   2   8   0   1   1   0   0\n",
      "    2   0]\n",
      " [  0   0   1   0   2   0   5 189  14   1   1   2   4   2   4   0   5   1\n",
      "    0   0]\n",
      " [  1   0   0   0   1   1   4  13 205   1   1   0   4   0   1   1   0   0\n",
      "    1   0]\n",
      " [  3   0   0   1   0   0   4   0   3 252   9   1   0   1   1   0   0   1\n",
      "    1   0]\n",
      " [  0   0   2   1   0   0   4   3   0  12 243   0   2   0   0   2   1   0\n",
      "    1   0]\n",
      " [  0   3   2   2   0   1   1   0   0   0   0 203   3   2   0   0   4   0\n",
      "    5   0]\n",
      " [  0  10   2  13   9   1  11   5   2   0   0   2 188   1   2   1   1   0\n",
      "    0   1]\n",
      " [  3   5   0   1   1   1   0   2   5   1   3   2  11 214   3   2   2   1\n",
      "    3   3]\n",
      " [  3   7   0   0   1   0   2   3   1   3   0   0   3   1 206   1   1   2\n",
      "    3   3]\n",
      " [ 14   2   1   0   0   1   0   0   1   2   1   0   3   3   0 220   0   4\n",
      "    1   9]\n",
      " [  0   0   0   0   0   0   3   1   3   1   1   7   1   1   0   1 228   1\n",
      "   14   8]\n",
      " [  7   0   0   0   1   1   0   0   0   1   0   1   2   0   0   4   3 190\n",
      "    8   6]\n",
      " [  8   0   2   1   0   0   1   3   2   1   0   0   0   4   3   4  56  20\n",
      "  150  17]\n",
      " [ 60   0   0   0   0   0   0   0   1   0   1   0   2   2   4  35  28   1\n",
      "   19  98]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))\n",
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7656"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#USING SKlearn INBUILT CLASSIFIER\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "y_pred2 = clf.predict(X_test)\n",
    "accuracy_score(Y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus accuracy for self coded classifier is very slightly higher than multinomial NB Classifier.\n",
    "#As we can see below, classification report is also nearly same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       236\n",
      "           1       0.68      0.66      0.67       242\n",
      "           2       0.65      0.77      0.70       231\n",
      "           3       0.68      0.68      0.68       259\n",
      "           4       0.74      0.74      0.74       246\n",
      "           5       0.89      0.73      0.80       252\n",
      "           6       0.75      0.77      0.76       264\n",
      "           7       0.77      0.81      0.79       231\n",
      "           8       0.80      0.89      0.84       234\n",
      "           9       0.89      0.91      0.90       277\n",
      "          10       0.93      0.88      0.91       271\n",
      "          11       0.91      0.89      0.90       226\n",
      "          12       0.68      0.76      0.71       249\n",
      "          13       0.90      0.81      0.86       263\n",
      "          14       0.88      0.86      0.87       240\n",
      "          15       0.78      0.83      0.80       262\n",
      "          16       0.69      0.84      0.76       270\n",
      "          17       0.87      0.83      0.85       224\n",
      "          18       0.72      0.55      0.62       272\n",
      "          19       0.53      0.39      0.45       251\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      5000\n",
      "   macro avg       0.77      0.77      0.76      5000\n",
      "weighted avg       0.77      0.77      0.76      5000\n",
      "\n",
      "[[169   1   0   1   0   0   0   3   5   1   1   0   2   2   1   9   1   1\n",
      "    1  38]\n",
      " [  0 160  23   7   6  13   4   4   0   0   0   3   6   5   9   1   0   0\n",
      "    0   1]\n",
      " [  0  14 172  16   5   9   4   0   0   1   0   2   4   0   0   0   0   0\n",
      "    3   1]\n",
      " [  0   5  26 177  25   0   7   5   1   0   0   2   9   0   1   0   0   1\n",
      "    0   0]\n",
      " [  0   4  11  20 184   0   7   3   0   0   0   0  13   2   1   0   1   0\n",
      "    0   0]\n",
      " [  1  26  22   5   3 185   1   0   0   0   0   1   5   0   3   0   0   0\n",
      "    0   0]\n",
      " [  2   2   2  15   6   0 202  11   7   1   2   2   8   0   1   1   0   0\n",
      "    2   0]\n",
      " [  0   0   1   0   2   0   5 189  14   1   1   2   4   2   4   0   5   1\n",
      "    0   0]\n",
      " [  1   0   0   0   1   1   4  13 205   1   1   0   4   0   1   1   0   0\n",
      "    1   0]\n",
      " [  3   0   0   1   0   0   4   0   3 252   9   1   0   1   1   0   0   1\n",
      "    1   0]\n",
      " [  0   0   2   1   0   0   4   3   0  12 243   0   2   0   0   2   1   0\n",
      "    1   0]\n",
      " [  0   3   2   2   0   1   1   0   0   0   0 203   3   2   0   0   4   0\n",
      "    5   0]\n",
      " [  0  10   2  13   9   1  11   5   2   0   0   2 188   1   2   1   1   0\n",
      "    0   1]\n",
      " [  3   5   0   1   1   1   0   2   5   1   3   2  11 214   3   2   2   1\n",
      "    3   3]\n",
      " [  3   7   0   0   1   0   2   3   1   3   0   0   3   1 206   1   1   2\n",
      "    3   3]\n",
      " [ 14   2   1   0   0   1   0   0   1   2   1   0   3   3   0 220   0   4\n",
      "    1   9]\n",
      " [  0   0   0   0   0   0   3   1   3   1   1   7   1   1   0   1 228   1\n",
      "   14   8]\n",
      " [  7   0   0   0   1   1   0   0   0   1   0   1   2   0   0   4   3 190\n",
      "    8   6]\n",
      " [  8   0   2   1   0   0   1   3   2   1   0   0   0   4   3   4  56  20\n",
      "  150  17]\n",
      " [ 60   0   0   0   0   0   0   0   1   0   1   0   2   2   4  35  28   1\n",
      "   19  98]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred2))\n",
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
